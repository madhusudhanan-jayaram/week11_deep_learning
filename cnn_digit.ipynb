{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ba7cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7d00905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the MNIST handwritten digit dataset (if not already cached locally)\n",
    "# URL: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
    "# Grayscale vs Color:\n",
    "# MNIST = Grayscale Images:\n",
    "# 1 channel (hence the \"1\" in input_shape = (28, 28, 1))\n",
    "# Black and white handwritten digits\n",
    "# Each pixel has one intensity value (0-255)\n",
    "# If it were Color Images:\n",
    "# 3 channels (RGB: Red, Green, Blue)\n",
    "# Input shape would be (28, 28, 3)\n",
    "# Each pixel would have three values (R, G, B)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ec5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset Information:\n",
      "========================================\n",
      "Training images shape: (60000, 28, 28)\n",
      "  - Number of training images: 60,000\n",
      "  - Image dimensions: 28 x 28 pixels\n",
      "\n",
      "Training labels shape: (60000,)\n",
      "  - Number of training labels: 60,000\n",
      "\n",
      "Test images shape: (10000, 28, 28)\n",
      "  - Number of test images: 10,000\n",
      "  - Image dimensions: 28 x 28 pixels\n",
      "\n",
      "Test labels shape: (10000,)\n",
      "  - Number of test labels: 10,000\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions (shapes) of the loaded datasets with meaningful print statements\n",
    "print(\"MNIST Dataset Information:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Training images shape: {x_train.shape}\")\n",
    "print(f\"  - Number of training images: {x_train.shape[0]:,}\")\n",
    "print(f\"  - Image dimensions: {x_train.shape[1]} x {x_train.shape[2]} pixels\")\n",
    "print()\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"  - Number of training labels: {y_train.shape[0]:,}\")\n",
    "print()\n",
    "print(f\"Test images shape: {x_test.shape}\")\n",
    "print(f\"  - Number of test images: {x_test.shape[0]:,}\")\n",
    "print(f\"  - Image dimensions: {x_test.shape[1]} x {x_test.shape[2]} pixels\")\n",
    "print()\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"  - Number of test labels: {y_test.shape[0]:,}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64ed4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to add channel dimension for CNN compatibility\n",
    "# Convert from (samples, height, width) to (samples, height, width, channels)\n",
    "# Before: x_train.shape = (60000, 28, 28) - 3D array\n",
    "# After: x_train.shape = (60000, 28, 28, 1) - 4D array with 1 channel (grayscale)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Define input shape for CNN model: (height, width, channels)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7f308d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of x_train: float32\n",
      "Data type of x_test: float32\n",
      "Data type of y_train: uint8\n",
      "Data type of y_test: uint8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data type of x_train: {x_train.dtype}\")\n",
    "print(f\"Data type of x_test: {x_test.dtype}\")\n",
    "print(f\"Data type of y_train: {y_train.dtype}\")\n",
    "print(f\"Data type of y_test: {y_test.dtype}\")\n",
    "\n",
    "# Convert from uint8 (0-255) to float32 for neural network compatibility\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e93473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this comment to clarify:\n",
    "# Normalize grayscale pixel intensities from 0-255 to 0.0-1.0 range\n",
    "# 0→0.0 (white/no ink), 128→0.502 (gray), 255→1.0 (black/full ink)\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06433144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CNN Model - Sequential Flow:\n",
      "==================================================\n",
      "1. Input Layer: (28, 28, 1) - Grayscale images\n",
      "2. Conv2D Layer: 28 filters, 3x3 kernel → Output: (26, 26, 28)\n",
      "   Why 26x26? (28-3+1) = 26 (no padding)\n",
      "3. MaxPooling2D: 2x2 pool → Output: (13, 13, 28)\n",
      "   Why 13x13? 26/2 = 13 (downsampling)\n",
      "4. Flatten: Convert 2D to 1D → Output: (4732,)\n",
      "   Why 4732? 13 × 13 × 28 = 4732 neurons\n",
      "5. Dense Layer: 128 neurons with ReLU activation\n",
      "6. Dropout: Randomly drop 20% of neurons (prevent overfitting)\n",
      "7. Output Layer: 10 neurons (digits 0-9) with Softmax\n",
      "==================================================\n",
      "Data Flow: 28×28×1 → 26×26×28 → 13×13×28 → 4732 → 128 → 10\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4732</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">605,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │           \u001b[38;5;34m280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4732\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m605,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">607,394</span> (2.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m607,394\u001b[0m (2.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">607,394</span> (2.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m607,394\u001b[0m (2.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build CNN model architecture with sequential flow explanation\n",
    "print(\"Building CNN Model - Sequential Flow:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "print(\"1. Input Layer: (28, 28, 1) - Grayscale images\")\n",
    "model.add(Conv2D(28, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "print(\"2. Conv2D Layer: 28 filters/channel depth(enhance the image information), 3x3 kernel, ReLU activation → Output: (26, 26, 28)\") #Most CNNs use 3×3 (VGG, ResNet, etc.)\n",
    "print(\"   Why 26x26? (28-3+1) = 26 (no padding)\")\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "print(\"3. MaxPooling2D: 2x2 pool → Output: (13, 13, 28)\")\n",
    "print(\"   Why 13x13? 26/2 = 13 (downsampling)\")\n",
    "\n",
    "model.add(Flatten())\n",
    "print(\"4. Flatten: Convert 2D to 1D → Output: (4732,)\")\n",
    "print(\"   Why 4732? 13 × 13 × 28 = 4732 neurons\")\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(\"5. Dense Layer: 128 neurons with ReLU activation\")\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "print(\"6. Dropout: Randomly drop 20% of neurons (prevent overfitting)\")\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"7. Output Layer: 10 neurons (digits 0-9) with Softmax\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Data Flow: 28×28×1 → 26×26×28 → 13×13×28 → 4732 → 128 → 10\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b80aed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 24ms/step - accuracy: 0.8536 - loss: 0.8102\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 25ms/step - accuracy: 0.9241 - loss: 0.2693\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 68ms/step - accuracy: 0.9421 - loss: 0.2064\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 91ms/step - accuracy: 0.9498 - loss: 0.1814\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 54ms/step - accuracy: 0.9543 - loss: 0.1623\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.9576 - loss: 0.1566\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 15ms/step - accuracy: 0.9601 - loss: 0.1446\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.9631 - loss: 0.1383\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.9637 - loss: 0.1376\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.9648 - loss: 0.1319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22a02e6bc40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://keras.io/api/optimizers/\n",
    "# Each epoch:\n",
    "# 1. Model makes predictions on training images\n",
    "# 2. Compares predictions with actual labels (loss calculation)\n",
    "# 3. Adjusts weights using Adam optimizer (backpropagation)\n",
    "# 4. Reports accuracy improvement\n",
    "# Configure model for training - Adam optimizer with crossentropy loss\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model for 10 epochs on 60,000 training images\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f260b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.1848\n",
      "\n",
      "Final Test Results:\n",
      "Test Accuracy: 0.9648 (96.48%)\n",
      "Test Loss: 0.1848\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained model performance on unseen test data (10,000 images)\n",
    "# Returns [test_loss, test_accuracy] - how well model performs on new data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b2bd3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "Predicted digit: 6\n",
      "Actual digit: 6\n",
      "Prediction confidence: 1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Visualize and test a single prediction from the test dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a specific test image (index 6900) to visualize and predict\n",
    "image_index = 6900\n",
    "\n",
    "# Display the selected test image as grayscale\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap='Greys')\n",
    "plt.title(f\"Test Image at Index {image_index}\")\n",
    "plt.show()\n",
    "\n",
    "# Prepare image for prediction (reshape to match model input: batch_size=1, height=28, width=28, channels=1)\n",
    "predict_image = x_test[image_index].reshape(1, 28, 28, 1)\n",
    "\n",
    "# Make prediction using trained model - returns probability distribution for all 10 digits\n",
    "pred = model.predict(predict_image)\n",
    "\n",
    "# Get the predicted digit (highest probability class)\n",
    "predicted_digit = pred.argmax()\n",
    "print(f\"Predicted digit: {predicted_digit}\")\n",
    "print(f\"Actual digit: {y_test[image_index]}\")\n",
    "print(f\"Prediction confidence: {pred[0][predicted_digit]:.4f} ({pred[0][predicted_digit]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "718e68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test set...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=uint8)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Step 1: Make predictions on entire test set (10,000 images)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking predictions on test set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m                    \u001b[38;5;66;03m# Get probability predictions\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)        \u001b[38;5;66;03m# Convert probabilities to class labels (0-9)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Step 2: Create confusion matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mukil\\anaconda3\\envs\\aiml\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mukil\\anaconda3\\envs\\aiml\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=uint8)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix to analyze model performance across all digit classes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Make predictions on entire test set (10,000 images)\n",
    "print(\"Making predictions on test set...\")\n",
    "y_pred = model.predict(x_test)                    # Get probability predictions\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)        # Convert probabilities to class labels (0-9)\n",
    "\n",
    "# Step 2: Create confusion matrix\n",
    "print(\"Creating confusion matrix...\")\n",
    "cm = confusion_matrix(y_test, y_pred_classes)     # Compare actual vs predicted labels\n",
    "\n",
    "# Step 3: Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, \n",
    "           annot=True,           # Show numbers in cells\n",
    "           fmt='d',              # Display as integers\n",
    "           cmap='Blues',         # Blue color scheme\n",
    "           xticklabels=range(10), # X-axis labels (0-9)\n",
    "           yticklabels=range(10)) # Y-axis labels (0-9)\n",
    "plt.title('Confusion Matrix - MNIST Digit Classification')\n",
    "plt.xlabel('Predicted Digit')\n",
    "plt.ylabel('Actual Digit')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Print detailed classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=[str(i) for i in range(10)]))\n",
    "\n",
    "# Step 5: Calculate per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "print(\"=\" * 30)\n",
    "for i in range(10):\n",
    "    # Diagonal elements = correct predictions for each digit\n",
    "    correct_predictions = cm[i, i]\n",
    "    # Row sum = total actual instances of each digit\n",
    "    total_actual = np.sum(cm[i, :])\n",
    "    # Calculate accuracy for this digit\n",
    "    class_accuracy = correct_predictions / total_actual\n",
    "    print(f\"Digit {i}: {correct_predictions:4d}/{total_actual:4d} = {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
